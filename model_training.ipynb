{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freddy/apps/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization, Cropping2D, Lambda, Activation, Dropout\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.initializers import glorot_normal\n",
    "from sklearn.utils import shuffle\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driving_log = pd.read_csv('data/driving_log.csv', names=['center','left','right','angle','throttle','brake','speed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_left_right_angle = driving_log[['center', 'left', 'right', 'angle']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processFilename(filename):\n",
    "  filename = filename.split('/')\n",
    "  filename = 'data/{}/{}'.format(filename[-2], filename[-1])\n",
    "  return filename\n",
    "# enddef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = plt.imread( processFilename(center_left_right_angle.iloc[0].center) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 320, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function reads the images into memory, it is not a scalable approach when there are too many images\n",
    "def read_angles(driving_log):\n",
    "  angles = []\n",
    "  for row in driving_log.itertuples():\n",
    "    angle = row.angle\n",
    "    angles.append(angle)\n",
    "  # end for\n",
    "  return np.array(angles)\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = read_angles(center_left_right_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq, boundaries = np.histogram(angles, bins=[-1.0, -0.4, -0.2, -0.1, -0.025, 0.025, 0.1, 0.2, 0.4, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = freq / np.sum(freq)\n",
    "prob = 1 - prob / np.max(prob)\n",
    "for i in zip(boundaries, prob):\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_angles = []\n",
    "for angle in angles:\n",
    "  augmented_angles.append(angle)\n",
    "  i = bisect.bisect_left(boundaries, -angle) - 1 # find angle in the boundaries\n",
    "  if np.random.rand() <= prob[i]:\n",
    "    augmented_angles.append(-angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(angles, bins=100)\n",
    "plt.xlabel('angle')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('histogram before augmentation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(augmented_angles, bins=100)\n",
    "plt.xlabel('angle')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('histogram after augmentation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1) # set the random number seed\n",
    "\n",
    "npts = len(center_left_right_angle)\n",
    "\n",
    "# center_left_right_angle contains all the rows\n",
    "# split into training and validation with a 0.8, 0.2 split\n",
    "\n",
    "npts_rand = np.random.rand(npts)\n",
    "train_set = center_left_right_angle[npts_rand <= 0.8]\n",
    "valid_set = center_left_right_angle[npts_rand >  0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data_set, batch_size):\n",
    "  N = len(data_set)\n",
    "  while True:\n",
    "    data_set = shuffle(data_set)\n",
    "    for offset in range(0, N, batch_size):\n",
    "      rows = data_set.iloc[offset:offset+batch_size]\n",
    "      images = []\n",
    "      angles = []\n",
    "      for row in rows.itertuples():\n",
    "        angle = row.angle\n",
    "\n",
    "#         i = bisect.bisect_left(boundaries, -angle) - 1 # find angle in the boundaries\n",
    "#         if np.random.rand() <= prob[i]:\n",
    "#           augment = True\n",
    "#         else:\n",
    "#           augment = False\n",
    "\n",
    "        augment = True\n",
    "        \n",
    "        # for center image\n",
    "        image = plt.imread( processFilename(row.center) )\n",
    "        images.append(image)\n",
    "        angles.append(angle)\n",
    "        if augment:\n",
    "          images.append(cv2.flip(image, 1))\n",
    "          angles.append(-angle)\n",
    "\n",
    "        # for left image\n",
    "        image = plt.imread( processFilename(row.left) )\n",
    "        images.append(image)\n",
    "        angles.append(angle + 0.2)\n",
    "        if augment:\n",
    "          images.append(cv2.flip(image, 1))\n",
    "          angles.append(-angle - 0.2)\n",
    "        \n",
    "\n",
    "        # for right image\n",
    "        image = plt.imread( processFilename(row.right) )\n",
    "        images.append(image)\n",
    "        angles.append(angle - 0.2)\n",
    "        if augment:\n",
    "          images.append(cv2.flip(image, 1))\n",
    "          angles.append(-angle + 0.2)\n",
    "        \n",
    "      #end for\n",
    "      images = np.array(images)\n",
    "      angles = np.array(angles)\n",
    "      \n",
    "      yield shuffle(images, angles)\n",
    "    #end for\n",
    "  #end while\n",
    "#end def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "train_generator = generator(train_set, batch_size)\n",
    "valid_generator = generator(valid_set, batch_size)\n",
    "\n",
    "steps_per_epoch  = np.rint(len(train_set) / batch_size).astype(int)\n",
    "validation_steps = np.rint(len(valid_set) / batch_size).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nvidia():\n",
    "  model = Sequential()\n",
    "  model.add(Cropping2D(cropping=((70,25), (0,0)), input_shape=(160,320,3)))\n",
    "  model.add(BatchNormalization())\n",
    "  \n",
    "  model.add(Conv2D(\n",
    "    24, 10, strides=2, padding='valid', \n",
    "    kernel_initializer=glorot_normal(seed=1), bias_initializer='zeros'\n",
    "  )) # (160 - 10)/2 + 1 = 76, (320 - 10)/2 + 1 = 156\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  \n",
    "  model.add(Conv2D(\n",
    "    36, 5, strides=2, padding='valid',\n",
    "    kernel_initializer=glorot_normal(seed=1), bias_initializer='zeros'\n",
    "  ))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  \n",
    "  model.add(Conv2D(\n",
    "    48, 5, strides=1, padding='valid',\n",
    "    kernel_initializer=glorot_normal(seed=1), bias_initializer='zeros'\n",
    "  ))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  \n",
    "  model.add(Conv2D(\n",
    "    64, 3, padding='valid',\n",
    "    kernel_initializer=glorot_normal(seed=1), bias_initializer='zeros'\n",
    "  ))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  \n",
    "  model.add(Conv2D(\n",
    "    64, 3, padding='valid',\n",
    "    kernel_initializer=glorot_normal(seed=1), bias_initializer='zeros'\n",
    "  ))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  \n",
    "  model.add(Flatten())\n",
    "\n",
    "  model.add(Dense(100, kernel_initializer=glorot_normal(seed=1), bias_initializer='zeros'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  \n",
    "  model.add(Dense(50, kernel_initializer=glorot_normal(seed=1), bias_initializer='zeros'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  \n",
    "  model.add(Dense(10, kernel_initializer=glorot_normal(seed=1), bias_initializer='zeros'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  \n",
    "  model.add(Dense(1, kernel_initializer=glorot_normal(seed=1), bias_initializer='zeros'))\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nvidia()\n",
    "optimizer = Adam(lr=1e-3)\n",
    "model.compile(loss='mse', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "336/336 [==============================] - 22s 65ms/step - loss: 0.0448 - val_loss: 0.0158\n",
      "Epoch 2/5\n",
      "336/336 [==============================] - 20s 61ms/step - loss: 0.0126 - val_loss: 0.0126\n",
      "Epoch 3/5\n",
      "336/336 [==============================] - 20s 61ms/step - loss: 0.0097 - val_loss: 0.0089\n",
      "Epoch 4/5\n",
      "336/336 [==============================] - 20s 61ms/step - loss: 0.0081 - val_loss: 0.0096\n",
      "Epoch 5/5\n",
      "336/336 [==============================] - 20s 61ms/step - loss: 0.0069 - val_loss: 0.0081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3cc0307ac8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "  train_generator, steps_per_epoch=steps_per_epoch, \n",
    "  epochs=5, \n",
    "  validation_data=valid_generator, validation_steps=validation_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('params/model.h5')\n",
    "model.save_weights('params/model_weights.h5')\n",
    "\n",
    "# json_string = model.to_json()\n",
    "# with open('params/model_architecture.json', 'w') as fid:\n",
    "#   fid.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function reads the images into memory, it is not a scalable approach when there are too many images\n",
    "def read_images(driving_log):\n",
    "  images = []\n",
    "  angles = []\n",
    "  for row in driving_log.itertuples():\n",
    "    angle = row.angle\n",
    "    \n",
    "    # for center image\n",
    "    image = plt.imread( processFilename(row.center) )\n",
    "    images.append(image)\n",
    "    angles.append(angle)\n",
    "    \n",
    "    # for left image\n",
    "    image = plt.imread( processFilename(row.left) )\n",
    "    images.append(image)\n",
    "    angles.append(angle + 0.2)\n",
    "    \n",
    "    # for right image\n",
    "    image = plt.imread( processFilename(row.right) )\n",
    "    images.append(image)\n",
    "    angles.append(angle - 0.2)\n",
    "    \n",
    "    # end if\n",
    "  # end for\n",
    "  return np.array(images), np.array(angles)\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, angles = read_images(center_left_right_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment the data set\n",
    "augmented_images = []\n",
    "augmented_angles = []\n",
    "for image, angle in zip(images, angles):\n",
    "  augmented_images.append(image)\n",
    "  augmented_angles.append(angle)\n",
    "  \n",
    "  augmented_images.append(cv2.flip(image, 1))\n",
    "  augmented_angles.append(-angle)\n",
    "# end for\n",
    "\n",
    "augmented_images = np.array(augmented_images)\n",
    "augmented_angles = np.array(augmented_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_use = 4\n",
    "for i in augmented_images.shape:\n",
    "  mem_use *= i\n",
    "print('memory use = gb', mem_use / np.power(2,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(augmented_angles, bins=100)\n",
    "plt.xlabel('angle')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('histogram after augmentation')\n",
    "plt.show()\n",
    "\n",
    "# as you can see, it is now normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_images = np.random.randint(0,images.shape[0],size=(3*3,))\n",
    "# plot images in original RGB mode\n",
    "plt.figure(figsize=(20,10))\n",
    "for idx, i in enumerate(random_images):\n",
    "  plt.subplot(3, 3, idx+1)\n",
    "  plt.imshow(images[i,:,:,:])\n",
    "  plt.title('{}. angle = {:.3g}'.format(idx, angles[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu   = np.mean(augmented_images)\n",
    "sigma = np.std(augmented_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mu={}, sigma={}'.format(mu, sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "  x=augmented_images, y=augmented_angles, \n",
    "  batch_size=200, epochs=5, verbose=1, validation_split=0.2, shuffle=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
