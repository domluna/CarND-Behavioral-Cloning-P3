{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the csv file 8037\n",
      "Training started...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 160, 320, 3)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)        (None, 65, 320, 3)    0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 31, 158, 24)   1824        cropping2d_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 14, 77, 36)    21636       convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 5, 37, 48)     43248       convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 5, 37, 48)     0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 3, 35, 64)     27712       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 1, 33, 64)     36928       convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 1, 33, 64)     0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 2112)          0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 512)           1081856     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 64)            32832       dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 64)            0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            650         dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             11          dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 1,246,697\n",
      "Trainable params: 1,246,697\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      " 647/6429 [==>...........................] - ETA: 218s - loss: 0.2349"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ef856978c9f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m \u001b[0mmainfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-ef856978c9f4>\u001b[0m in \u001b[0;36mmainfn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;31m#print('generator invoked train {} valid {}'.format(train_generator, valid_generator))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m     \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[0mmainfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-ef856978c9f4>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(train_generator, valid_generator, len_train, len_valid)\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;31m#model.fit(X, y, validation_split=0.2, shuffle=True, verbose=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mlen_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_val_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training complete!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Total time for training {:.3f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    933\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[0;32m   1551\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   1552\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1553\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1555\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1314\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1316\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1317\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1898\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1899\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m-> 1900\u001b[1;33m                               feed_dict=feed_dict)\n\u001b[0m\u001b[0;32m   1901\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 766\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 964\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    965\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1014\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1015\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1003\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def read_file(filename):\n",
    "    lines = []\n",
    "    with open(filename) as csvfile:\n",
    "        data_rows = csv.reader(csvfile)\n",
    "        for row in data_rows:\n",
    "            lines.append(row)\n",
    "    return lines\n",
    "\n",
    "#This crops to (72, 320, 3)\n",
    "def crop_images(X, y):\n",
    "    images = []\n",
    "    image_for_plot = []\n",
    "    steering_angles = []\n",
    "    top_percent = 0.4\n",
    "    bottom_percent = 0.15\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        ind_img = X[i]\n",
    "        top = int(np.ceil(ind_img.shape[0] * top_percent))\n",
    "        bottom = ind_img.shape[0] - int(np.ceil(ind_img.shape[0] * bottom_percent))\n",
    "        cropped_img = ind_img[top:bottom, :]\n",
    "        images.append(cropped_img)\n",
    "        image_for_plot.append(ind_img)\n",
    "        image_for_plot.append(cropped_img)\n",
    "        steering_angles.append(y[i])\n",
    "    #print('cropped -->', images[-1].shape, images[1].shape)\n",
    "\n",
    "    #Plot Images\n",
    "#     print('Original {} Cropped {}'.format(image_for_plot[0].shape, image_for_plot[1].shape))\n",
    "#     fig, axs = plt.subplots(1, 2, figsize=(14, 12))\n",
    "#     fig.subplots_adjust(hspace = .4, wspace=.2)\n",
    "#     axs = axs.ravel()\n",
    "#     axs[0].axis('off')\n",
    "#     axs[0].imshow(image_for_plot[0])\n",
    "#     axs[0].set_title('Original Image', fontsize=22)\n",
    "#     axs[1].axis('off')\n",
    "#     axs[1].imshow(image_for_plot[1])\n",
    "#     axs[1].set_title('Cropped Image', fontsize=22)\n",
    "#     plt.show()\n",
    "    return images, steering_angles\n",
    "\n",
    "#This resizes to (66, 200, 3)\n",
    "#Without resizing gave better results, hence don't use this\n",
    "def resize_images(X, y):\n",
    "    images = []\n",
    "    image_for_plot = []\n",
    "    steering_angles = []\n",
    "    for i in range(len(X)):\n",
    "        resized = cv2.resize(X[i], (200, 66))\n",
    "        images.append(resized)\n",
    "        steering_angles.append(y[i])\n",
    "        image_for_plot.append(X[i])\n",
    "        image_for_plot.append(resized)\n",
    "    #print('resize --> ', images[1].shape)\n",
    "#     print('Cropped {} Resized {}'.format(image_for_plot[0].shape, image_for_plot[1].shape))\n",
    "#     fig, axs = plt.subplots(1, 2, figsize=(14, 12))\n",
    "#     fig.subplots_adjust(hspace = .4, wspace=.2)\n",
    "#     axs = axs.ravel()\n",
    "#     axs[0].axis('off')\n",
    "#     axs[0].imshow(image_for_plot[0])\n",
    "#     axs[0].set_title('Cropped Image', fontsize=22)\n",
    "#     axs[1].axis('off')\n",
    "#     axs[1].imshow(image_for_plot[1])\n",
    "#     axs[1].set_title('Resized Image', fontsize=22)\n",
    "#     plt.show()\n",
    "    return images, steering_angles\n",
    "\n",
    "    \n",
    "def apply_gamma(X, y):\n",
    "    images = []\n",
    "    steering_angles = []\n",
    "    image_for_plot = []\n",
    "    for i in range(len(X)):\n",
    "        gamma = np.random.uniform(0.7, 1.7)\n",
    "        inv_gamma = 1 / gamma\n",
    "        map_table = np.array([((i/255.0)**inv_gamma)*255 for i in np.arange(0,256)])\n",
    "        transformed_img = cv2.LUT(X[i], map_table)\n",
    "        images.append(X[i])\n",
    "        steering_angles.append(y[i])\n",
    "        images.append(transformed_img)\n",
    "        steering_angles.append(y[i])\n",
    "        image_for_plot.append(X[i])\n",
    "        image_for_plot.append(transformed_img)\n",
    "\n",
    "#     print('Resized {} Gamma {}'.format(image_for_plot[0].shape, image_for_plot[1].shape))\n",
    "#     fig, axs = plt.subplots(1, 2, figsize=(14, 12))\n",
    "#     fig.subplots_adjust(hspace = .4, wspace=.2)\n",
    "#     axs = axs.ravel()\n",
    "#     axs[0].axis('off')\n",
    "#     axs[0].imshow(image_for_plot[0])\n",
    "#     axs[0].set_title('Resized Image', fontsize=22)\n",
    "#     axs[1].axis('off')\n",
    "#     axs[1].imshow(image_for_plot[1])\n",
    "#     axs[1].set_title('Gamma Image', fontsize=22)\n",
    "#     plt.show()\n",
    "    return images, steering_angles\n",
    "\n",
    "def vary_brightness(X, y):\n",
    "    images = []\n",
    "    steering_angles = []\n",
    "    for i in range(len(X)):\n",
    "        # HSV (Hue, Saturation, Value) - Value is brightness\n",
    "        hsv_img = cv2.cvtColor(X[i], cv2.COLOR_RGB2HSV)\n",
    "        random_value = 1.0 + 0.6 * (np.random.rand() - 0.5)\n",
    "        hsv_img[:,:,2] =  hsv_img[:,:,2] * random_value\n",
    "        transformed_img =  cv2.cvtColor(hsv_img, cv2.COLOR_HSV2RGB)\n",
    "        images.append(transformed_img)\n",
    "        steering_angles.append(y[i])\n",
    "    return images, steering_angles\n",
    "\n",
    "    \n",
    "def add_shadow(X, y):\n",
    "    images = []\n",
    "    steering_angles = []\n",
    "    image_for_plot = []\n",
    "    width, height = X[0].shape[:2]\n",
    "    for i in range(len(X)):\n",
    "        x1, y1 = width * np.random.rand(), 0\n",
    "        x2, y2 = width * np.random.rand(), height\n",
    "        xm, ym = np.mgrid[0:height, 0:width]\n",
    "        original_img = X[i]\n",
    "        mask = np.zeros_like(original_img[:, :, 1])\n",
    "        mask[(ym - y1) * (x2 - x1) - (y2 - y1) * (xm - x1) > 0] = 1\n",
    "\n",
    "        # choose which side should have shadow and adjust saturation\n",
    "        cond = mask == np.random.randint(2)\n",
    "        s_ratio = np.random.uniform(low=0.2, high=0.5)\n",
    "\n",
    "        # adjust Saturation in HLS(Hue, Light, Saturation)\n",
    "        hls = cv2.cvtColor(X[i], cv2.COLOR_RGB2HLS)\n",
    "        hls[:, :, 1][cond] = hls[:, :, 1][cond] * s_ratio\n",
    "        shadowed_img = cv2.cvtColor(hls, cv2.COLOR_HLS2RGB)\n",
    "        images.append(original_img)\n",
    "        steering_angles.append(y[i])\n",
    "        images.append(shadowed_img)\n",
    "        steering_angles.append(y[i])\n",
    "    image_for_plot.append(X[0])\n",
    "    image_for_plot.append(X[1])\n",
    "    image_for_plot.append(X[2])\n",
    "    image_for_plot.append(X[3])\n",
    "    \n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(14, 12))\n",
    "    fig.subplots_adjust(hspace = .4, wspace=.2)\n",
    "    axs = axs.ravel()\n",
    "    axs[0].axis('off')\n",
    "    axs[0].imshow(image_for_plot[0])\n",
    "    axs[0].set_title('Original', fontsize=22)\n",
    "    axs[1].axis('off')\n",
    "    axs[1].imshow(image_for_plot[1])\n",
    "    axs[1].set_title('Shadowed', fontsize=22)\n",
    "    axs[1].axis('off')\n",
    "    axs[1].imshow(image_for_plot[2])\n",
    "    axs[1].set_title('Original', fontsize=22)\n",
    "    axs[1].axis('off')\n",
    "    axs[1].imshow(image_for_plot[3])\n",
    "    axs[1].set_title('Shadowed', fontsize=22)\n",
    "    plt.show()\n",
    "    return images, steering_angles\n",
    "\n",
    "def flip_images_and_add(X, y):\n",
    "    #print('size before', len(X))\n",
    "    images = []\n",
    "    steering_angles = []\n",
    "    image_for_plot = []\n",
    "    for i in range(len(X)):\n",
    "        #print('less or greater {}'.format(y[i]))\n",
    "        images.append(X[i])\n",
    "        steering_angles.append(y[i])\n",
    "        #Flip only those images where there are curves\n",
    "        if y[i] < -0.1 or y[i] > 0.1 :\n",
    "            images.append(cv2.flip(X[i], 1))\n",
    "            steering_angles.append(y[i] * -1.0)\n",
    "        image_for_plot.append(X[i])\n",
    "        image_for_plot.append(cv2.flip(X[i], 1))\n",
    "#     print('Gamma {} Flipped {}'.format(image_for_plot[0].shape, image_for_plot[1].shape))\n",
    "#     fig, axs = plt.subplots(1, 2, figsize=(14, 12))\n",
    "#     fig.subplots_adjust(hspace = .4, wspace=.2)\n",
    "#     axs = axs.ravel()\n",
    "#     axs[0].axis('off')\n",
    "#     axs[0].imshow(image_for_plot[0])\n",
    "#     axs[0].set_title('Gamma Image', fontsize=22)\n",
    "#     axs[1].axis('off')\n",
    "#     axs[1].imshow(image_for_plot[1])\n",
    "#     axs[1].set_title('Flipped Image', fontsize=22)\n",
    "#     plt.show()\n",
    "    return images, steering_angles\n",
    "\n",
    "def translate(X, y, range_x, range_y):\n",
    "    #print('inside translate')\n",
    "    images = []\n",
    "    steering_angles = []\n",
    "    image_for_plot = []\n",
    "    angle_for_plot = []\n",
    "    for i in range(len(X)):\n",
    "        trans_x = range_x * (np.random.rand() - 0.5)\n",
    "        trans_y = range_y * (np.random.rand() - 0.5)\n",
    "        transformed_angle = y[i] + trans_x * 0.002\n",
    "        trans_m = np.float32([[1, 0, trans_x], [0, 1, trans_y]])\n",
    "        height, width = X[i].shape[:2]\n",
    "        transformed_img = cv2.warpAffine(X[i], trans_m, (width, height))\n",
    "#         image_for_plot.append(X[i])\n",
    "#         angle_for_plot.append(y[i])\n",
    "#         image_for_plot.append(transformed_img)\n",
    "#         angle_for_plot.append(transformed_angle)\n",
    "        images.append(X[i])\n",
    "        steering_angles.append(y[i])\n",
    "        #print(X[i].shape)\n",
    "        images.append(transformed_img)\n",
    "        steering_angles.append(transformed_angle)\n",
    "        #print('diff {} actual {} transformed {} '.format(y[i] - transformed_angle, y[i], transformed_angle))\n",
    "\n",
    "#     fig, axs = plt.subplots(1, 2, figsize=(14, 12))\n",
    "#     fig.subplots_adjust(hspace = .4, wspace=.2)\n",
    "#     axs = axs.ravel()\n",
    "#     axs[0].axis('off')\n",
    "#     axs[0].imshow(image_for_plot[0])\n",
    "#     axs[0].set_title(angle_for_plot[0], fontsize=22)\n",
    "#     axs[1].axis('off')\n",
    "#     axs[1].imshow(image_for_plot[1])\n",
    "#     axs[1].set_title(angle_for_plot[1], fontsize=22)\n",
    "#     plt.show()\n",
    "    return images, steering_angles\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def data_generator(rows, validation_flag, batch_size):\n",
    "    correction_factor = 0.20\n",
    "    path = 'trainingdata/IMG/'\n",
    "    len_rows = len(rows)\n",
    "    rows = shuffle(rows)\n",
    "    while 1:\n",
    "        for offset in range(0, len_rows, batch_size):\n",
    "            batch_rows = rows[offset:offset+batch_size]\n",
    "            images = []\n",
    "            steering_values = []\n",
    "            #print('rows in batch', len(batch_rows))\n",
    "            for line in batch_rows:\n",
    "                \n",
    "                center_image_path = line[0]\n",
    "                left_image_path = line[1]\n",
    "                right_image_path = line[2]\n",
    "\n",
    "                center_image_name = center_image_path.split('/')[-1] #Last token [-1] is the image\n",
    "                left_image_name = left_image_path.split('/')[-1]\n",
    "                right_image_name = right_image_path.split('/')[-1]\n",
    "\n",
    "                center_image_bgr = cv2.imread(path+center_image_name)\n",
    "                left_image_bgr   = cv2.imread(path+left_image_name)\n",
    "                right_image_bgr = cv2.imread(path+right_image_name)\n",
    "                \n",
    "                #Converting from BGR to RGB space as simulator reads RGB space\n",
    "                center_image = cv2.cvtColor(center_image_bgr, cv2.COLOR_BGR2RGB)\n",
    "                left_image   = cv2.cvtColor(left_image_bgr, cv2.COLOR_BGR2RGB)\n",
    "                right_image = cv2.cvtColor(right_image_bgr, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                \n",
    "\n",
    "                steering_value = float(line[3])\n",
    "                left_steering_value = steering_value + correction_factor\n",
    "                right_steering_value = steering_value - correction_factor\n",
    "                \n",
    "#                 images.append(cv2.GaussianBlur(center_image, (3, 3), 0))\n",
    "                images.append(center_image)\n",
    "                steering_values.append(steering_value)\n",
    "\n",
    "#                 images.append(cv2.GaussianBlur(left_image, (3, 3), 0))\n",
    "                images.append(left_image)\n",
    "                steering_values.append(left_steering_value)\n",
    "                \n",
    "#                 images.append(cv2.GaussianBlur(right_image, (3, 3), 0))\n",
    "                images.append(right_image)\n",
    "                steering_values.append(right_steering_value)\n",
    "                \n",
    "            \n",
    "            X_train, y_train = images, steering_values\n",
    "            X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "            #Augmenting & Pre-processing\n",
    "            #X_train, y_train = crop_images(X_train, y_train)\n",
    "            #X_train, y_train = resize_images(X_train, y_train)\n",
    "            X_train, y_train = translate(X_train, y_train, 100, 10)\n",
    "            X_train, y_train = flip_images_and_add(X_train, y_train)\n",
    "            X_train, y_train = vary_brightness(X_train, y_train)\n",
    "            #X_train, y_train = add_shadow(X_train, y_train)\n",
    "            X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "            X_train = np.array(X_train)\n",
    "            y_train = np.array(y_train)\n",
    "            \n",
    "            yield X_train, y_train\n",
    "\n",
    "        \n",
    "\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Dropout, Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "\n",
    "#def train_model(X, y):\n",
    "\n",
    "#Architecture based on NVIDIA\n",
    "def train_model(train_generator, valid_generator, len_train, len_valid):\n",
    "    print('Training started...')\n",
    "\n",
    "    model = Sequential()\n",
    "    #model.add(Lambda(lambda x: (x / 255) - 0.5, input_shape=(72, 320, 3)))\n",
    "    model.add(Lambda(lambda x: (x / 255) - 0.5, input_shape=(160, 320, 3)))\n",
    "    model.add(Cropping2D(cropping=((70, 25), (0, 0))))\n",
    "    #model.add(Reshape((55, 135)))\n",
    "    model.add(Convolution2D(24, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(Convolution2D(36, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(Convolution2D(48, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='elu'))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='elu'))\n",
    "    model.add(Dense(64, activation='elu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(10, activation='elu'))\n",
    "    model.add(Dense(1))\n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    #model.fit(X, y, validation_split=0.2, shuffle=True, verbose=1)\n",
    "    model.fit_generator(train_generator, samples_per_epoch= len_train, validation_data=valid_generator, nb_val_samples=len_valid, nb_epoch=10)\n",
    "    print('Training complete!')\n",
    "    print('Total time for training {:.3f}'.format(time.time() - start_time))\n",
    "    model.save('model.h5')\n",
    "\n",
    "    \n",
    "\n",
    "def mainfn():\n",
    "    data_rows = read_file('./trainingdata/driving_log.csv')\n",
    "    print('Length of the csv file {}'.format(len(data_rows)))\n",
    "    \n",
    "    rows_train, rows_valid = train_test_split(data_rows, test_size=0.2)\n",
    "    #print('splitting done {} {}'.format(len(rows_train), len(rows_valid)))\n",
    "    \n",
    "    train_generator = data_generator(rows_train, False, batch_size = 32)\n",
    "    valid_generator = data_generator(rows_valid, True, batch_size = 32)\n",
    "    #print('generator invoked train {} valid {}'.format(train_generator, valid_generator))\n",
    "    \n",
    "    train_model(train_generator, valid_generator, len(rows_train), len(rows_valid))\n",
    "\n",
    "mainfn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
